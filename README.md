# ğŸ¥ MedLens AI â€” Real-Time Medical Emergency Triage & First-Aid Coach

> **Vision Agents SDK Hackathon** â€” A multi-modal AI agent that watches, listens, and guides you through medical emergencies in real-time.

[![Vision Agents SDK](https://img.shields.io/badge/Powered%20by-Vision%20Agents%20SDK-blue)](https://visionagents.ai)
[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![React](https://img.shields.io/badge/frontend-React%2019-61dafb.svg)](https://react.dev)

---

## ğŸ¯ What is MedLens AI?

MedLens AI is a **real-time first-aid assistant** that uses your camera and microphone to:

1. **See** â€” YOLO pose detection identifies body positioning and movement in real-time
2. **Think** â€” DeepSeek R1 (via OpenRouter) provides intelligent medical guidance
3. **Listen** â€” Deepgram STT provides hands-free voice interaction (your hands are busy helping!)
4. **Guide** â€” ElevenLabs TTS speaks calm, step-by-step first-aid instructions
5. **Triage** â€” Classifies emergencies using standard triage categories (GREEN/YELLOW/RED/BLACK)
6. **Alert** â€” Can call emergency services with a structured briefing for critical situations

### ğŸ’¡ The Problem

In medical emergencies, people panic. They don't know what to do. Googling "how to do CPR" with bloody hands isn't practical. MedLens AI turns your phone or laptop into a **real-time first-aid coach** â€” it watches what's happening, understands the severity, and talks you through it step by step.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     Stream Edge      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  â”‚    (Ultra-Low         â”‚                  â”‚
â”‚  React Frontend  â”‚â—„â”€â”€  Latency)  â”€â”€â”€â”€â”€â”€â–ºâ”‚  MedLens Agent   â”‚
â”‚  (Video + Audio) â”‚    ~30ms             â”‚  (Python)        â”‚
â”‚                  â”‚                      â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                        â”‚
        â”‚ Camera + Mic                           â”‚ Processes
        â–¼                                        â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  User   â”‚                          â”‚ DeepSeek R1      â”‚ â† LLM (via OpenRouter)
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚ YOLO Pose        â”‚ â† Body detection (5fps)
                                        â”‚ Deepgram STT     â”‚ â† Speech to text
                                        â”‚ ElevenLabs TTS   â”‚ â† Text to speech
                                        â”‚ Tool Calling     â”‚ â† Emergency services
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Purpose |
|---|---|---|
| **Edge Network** | Stream | Ultra-low latency video/audio transport (~30ms) |
| **Vision LLM** | DeepSeek R1 (via OpenRouter) | Intelligent medical guidance & reasoning |
| **Pose Detection** | Ultralytics YOLO | Body/pose awareness for injury assessment |
| **Speech-to-Text** | Deepgram | Hands-free voice input with eager turn detection |
| **Text-to-Speech** | ElevenLabs Flash v2.5 | Natural, calm voice output |
| **Frontend** | React 19 + Stream Video SDK | Video call UI with triage dashboard |
| **Backend** | Python 3.12 + Vision Agents SDK | Agent orchestration and tool calling |

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+
- Node.js 18+
- [uv](https://docs.astral.sh/uv/) (Python package manager)
- API keys (see below)

### 1. Clone & Install

```bash
git clone https://github.com/preeeetham/medlens-ai.git
cd medlens-ai

# Backend
uv sync

# Frontend
cd frontend && npm install && cd ..
```

### 2. Configure API Keys

```bash
cp .env.example .env
```

Fill in your `.env`:
| Key | Get it from |
|---|---|
| `STREAM_API_KEY` / `STREAM_API_SECRET` | [getstream.io](https://getstream.io/try-for-free) |
| `OPENROUTER_API_KEY` | [OpenRouter](https://openrouter.ai/keys) |
| `ELEVENLABS_API_KEY` | [ElevenLabs](https://elevenlabs.io/app/settings/api-keys) |
| `DEEPGRAM_API_KEY` | [Deepgram](https://console.deepgram.com) |

### 3. Run the Agent

```bash
# Console mode (opens built-in demo UI)
uv run agent/main.py run

# OR server mode (for frontend integration)
uv run agent/main.py serve
```

### 4. Run the Frontend (optional â€” for custom UI)

```bash
cd frontend
npm run dev
```

Open `http://localhost:5173` and enter your Stream credentials to connect.

---

## ğŸ“¦ Project Structure

```
medlens-ai/
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ main.py                 # Agent entry point (Gemini Realtime + YOLO + tools)
â”‚   â”œâ”€â”€ medlens_instructions.md # Agent personality & first-aid protocols
â”‚   â””â”€â”€ knowledge/              # RAG knowledge base
â”‚       â”œâ”€â”€ first_aid_protocols.md
â”‚       â””â”€â”€ emergency_procedures.md
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx             # Root with StreamVideo provider
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Landing.jsx     # Connection page
â”‚   â”‚   â”‚   â”œâ”€â”€ VideoSession.jsx # Live video call UI
â”‚   â”‚   â”‚   â”œâ”€â”€ Header.jsx      # Status header
â”‚   â”‚   â”‚   â””â”€â”€ EmergencyPanel.jsx # Triage + activity log
â”‚   â”‚   â””â”€â”€ index.css           # Premium dark medical theme
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ .env.example
â”œâ”€â”€ RESOURCES.md                # SDK docs & reference links
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

---

## ğŸ¥ Features Deep Dive

### Real-Time Triage Classification
The agent classifies every situation using standard triage categories:
- ğŸŸ¢ **GREEN** â€” Minor injuries (small cuts, bruises). Self-treatable.
- ğŸŸ¡ **YELLOW** â€” Needs attention but stable (moderate burns, deep cuts).
- ğŸ”´ **RED** â€” Life-threatening, urgent (cardiac arrest, severe bleeding, choking).
- âš« **BLACK** â€” Beyond first-aid help (requires advanced medical intervention).

### Voice-Guided First Aid
Covers protocols for: burns (1st/2nd/3rd degree), cuts & lacerations, choking (Heimlich), CPR, fractures, seizures, allergic reactions (anaphylaxis + EpiPen), heatstroke, poisoning, nosebleeds, and more.

### YOLO Pose Detection
Real-time body pose analysis at 15fps helps the agent understand:
- Body positioning (standing, lying down, recovery position)
- Technique verification (CPR compressions, Heimlich grip)
- Number of people in frame

### Emergency Services Integration
When detecting life-threatening emergencies, the agent can trigger an emergency call with:
- Situation summary
- Severity classification
- Number of injured
- Injuries detected

---

## ğŸ”‘ Vision Agents SDK Features Used

| Feature | How We Use It |
|---|---|
| **DeepSeek R1 (OpenRouter)** | LLM for medical reasoning & guidance |
| **YOLO Processor** | Pose detection for body awareness |
| **Deepgram STT** | Hands-free voice input |
| **ElevenLabs TTS** | Natural voice guidance |
| **Stream Edge** | Ultra-low latency video transport |
| **Tool Calling** | Emergency services, triage classification, incident logging |
| **Event System** | Connection monitoring, error handling |
| **Instructions (MD)** | Agent personality and medical protocols |

---

## ğŸ“„ License

MIT â€” Built for the [Vision Agents Hackathon](https://www.wemakedevs.org/hackathons/vision) by WeMakeDevs.
